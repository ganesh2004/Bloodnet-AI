# BloodNet AI - Blood Bank Demand Prediction & Donor Matching

AI-powered blood demand forecasting and intelligent donor matching system for blood bank operations.

## ğŸ¯ Project Overview

BloodNet AI is a comprehensive machine learning system that:
- **Predicts blood demand** (RBC, Platelet, Plasma) across multiple time horizons
- **Matches donors** to predicted demand using intelligent scoring algorithms
- **Minimizes shortages** while maintaining high prediction accuracy (RÂ² > 0.85)
- **Optimizes donor outreach** based on compatibility, proximity, and response history

## ğŸ† Key Features

### 1. Multi-Horizon Demand Prediction
- **Short-term (1-7 days)**: High-accuracy regression for daily operations
- **Mid-term (7-30 days)**: Regression with lag features for planning
- **Long-term (30-90 days)**: Classification for strategic decisions

### 2. High Performance Models
| Component | Model | RÂ² Score | Undersupply Rate | Buffer |
|-----------|-------|----------|------------------|--------|
| RBC | LightGBM | 0.86 | 2.78% | +8% |
| Platelet | XGBoost | 0.86 | 0.00% (Perfect!) | +8% |
| Plasma | LightGBM | 0.88 | 15.28% | +5% |

### 3. Intelligent Donor Matching
- Blood type compatibility matrix
- Geographic proximity scoring (haversine distance)
- Historical response rate weighting
- Donation recency and frequency factors
- Urgency-based prioritization

### 4. Blood Group Disaggregation
Predicts demand for 8 blood groups: O+, O-, A+, A-, B+, B-, AB+, AB-

## ğŸ“ Repository Structure

```
Bloodnet-AI/
â”œâ”€â”€ src/                           # Source code
â”‚   â”œâ”€â”€ generate_dataset.py       # Synthetic data generation
â”‚   â”œâ”€â”€ split_dataset.py          # Dataset splitting by component
â”‚   â”œâ”€â”€ fix_and_improve_correlations.py  # Data enhancement
â”‚   â”œâ”€â”€ test_improved_predictions.py     # Model testing
â”‚   â”œâ”€â”€ check_undersupply_metric.py      # Undersupply analysis
â”‚   â”œâ”€â”€ optimize_for_undersupply.py      # Buffer optimization
â”‚   â”œâ”€â”€ test_prophet_and_cnn.py          # Additional models
â”‚   â”œâ”€â”€ donor_matching.py                # Donor matching algorithm
â”‚   â””â”€â”€ synthetic_donor_data.py          # Donor profile generation
â”‚
â”œâ”€â”€ data/                          # Datasets
â”‚   â”œâ”€â”€ improved_rbc_demand.csv    # Enhanced RBC dataset
â”‚   â”œâ”€â”€ improved_platelet_demand.csv
â”‚   â””â”€â”€ improved_plasma_demand.csv
â”‚
â”œâ”€â”€ docs/                          # Documentation
â”‚   â”œâ”€â”€ PROJECT_DESCRIPTION.txt    # Comprehensive guide (55 KB)
â”‚   â””â”€â”€ IMPROVEMENTS_SUMMARY.md    # Technical details
â”‚
â”œâ”€â”€ models/                        # Trained models (gitignored)
â”œâ”€â”€ notebooks/                     # Jupyter notebooks
â””â”€â”€ tests/                         # Unit tests

```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- Virtual environment (recommended)

### Installation

1. Clone the repository:
```bash
git clone <your-repo-url>
cd Bloodnet-AI
```

2. Create and activate virtual environment:
```bash
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

### Usage

#### 1. Generate Enhanced Dataset
```bash
cd src
python generate_dataset.py           # Creates synthetic data
python split_dataset.py              # Splits by component
python fix_and_improve_correlations.py  # Enhances correlations
```

This creates `improved_rbc_demand.csv`, `improved_platelet_demand.csv`, `improved_plasma_demand.csv`

#### 2. Train and Test Models
```bash
python test_improved_predictions.py  # Test all main models
python test_prophet_and_cnn.py       # Test Prophet and CNN
```

#### 3. Optimize for Undersupply
```bash
python optimize_for_undersupply.py   # Find optimal buffers
```

#### 4. Donor Matching
```bash
python donor_matching.py             # Match donors to demand
```

Outputs: `ranked_donors.json`

## ğŸ“Š Model Performance

### Models Tested
- âœ… **LightGBM** (selected for RBC, Plasma)
- âœ… **XGBoost** (selected for Platelet)
- âœ… RandomForest
- âš ï¸ CNN (decent but computationally expensive)
- âŒ Prophet (failed - dataset too short)
- âš ï¸ SARIMAX (moderate performance)

### Performance Metrics

**Without Buffer** (high accuracy, high undersupply):
- RBC: RÂ² = 0.97, Undersupply = 61% âŒ
- Platelet: RÂ² = 0.99, Undersupply = 43% âŒ
- Plasma: RÂ² = 0.93, Undersupply = 56% âŒ

**With Optimal Buffer** (balanced):
- RBC: RÂ² = 0.86, Undersupply = 2.78% âœ…
- Platelet: RÂ² = 0.86, Undersupply = 0.00% âœ… (Perfect!)
- Plasma: RÂ² = 0.88, Undersupply = 15.28% âœ…

### Why Buffer Strategy?
In blood banking, **undersupply is 100-1000Ã— more costly** than oversupply:
- Undersupply â†’ Patient harm, cancelled procedures ($50k-500k per event)
- Oversupply â†’ Some waste, but zero patient harm ($100-500 per unit)

We intentionally **overpredict by 5-8%** to prevent critical shortages.

## ğŸ”¬ Undersupply Metric

**Definition**: Prediction is insufficient when `(prediction + tolerance) < actual`

**Tolerance**: 2 units (accounts for rounding/statistical noise)

**Why it matters**:
- Asymmetric costs: Shortage >> Waste
- Patient safety is paramount
- RÂ² alone doesn't capture operational risk

## ğŸ“ˆ Dataset Features

### Temporal Features (7)
- date, day_of_week, week_of_year, month
- is_weekend, is_holiday

### Clinical Indicators (21)
- **RBC**: Hb counts, surgery types, dialysis, bleeding
- **Platelet**: Platelet counts, chemo patients, procedures
- **Plasma**: Coagulation abnormalities, trauma protocols

### Environmental (3)
- temperature, precipitation, air quality

### Targets (24)
- Total demand + 8 blood group disaggregations per component

## ğŸ“ Methodology

### Data Enhancement Process
1. **Problem**: Initial synthetic data had weak correlations (<0.3)
2. **Solution**: Reconstruct targets using clinically-informed weighted formulas
3. **Result**: Correlations improved to 0.48-0.98

### RBC Demand Formula Example:
```
rbc_demand = 
  count_hb_below_7 Ã— 25 +
  cardiac_surgeries Ã— 40 +
  trauma_admissions Ã— 30 +
  ... (11 weighted features)
  - is_weekend Ã— 2000 +
  + random_noise(0, 200)
```

Weights based on clinical transfusion protocols.

## ğŸ§  Donor Matching Algorithm

### Scoring Formula (0-100 points):
- **Blood compatibility**: 40% (exact match vs compatible)
- **Proximity**: 25% (distance to blood bank)
- **Response rate**: 20% (historical behavior)
- **Recency**: 10% (donation eligibility)
- **Frequency**: 5% (lifetime donations)

### Constraints:
- Donation interval: â‰¥56 days (whole blood)
- Notification cooldown: â‰¥14 days (prevent fatigue)
- Age: 18-65 years
- Oversampling: 3Ã— (accounts for 30-40% response rate)

## ğŸ“š Documentation

- **PROJECT_DESCRIPTION.txt**: Comprehensive 55 KB guide covering:
  - Step-by-step data generation
  - All 8 models tested (with rationale for selection/rejection)
  - Undersupply metric deep dive
  - Production deployment guide
  
- **IMPROVEMENTS_SUMMARY.md**: Technical correlation improvements

## ğŸ¤ Contributing

Contributions welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Test your changes
4. Submit a pull request

## ğŸ“„ License

[Add your license here]

## ğŸ‘¥ Authors

- [Your Name/Team]

## ğŸ™ Acknowledgments

- Clinical transfusion protocols based on WHO guidelines
- Blood type distribution for Indian population
- Haversine distance for geographic calculations

## ğŸ“§ Contact

[Your contact information]

---

**Note**: This project uses synthetic data for demonstration. In production, connect to real hospital information systems (EMR/HIS) for actual census and lab data.
